{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G_B1SeZFZ9Z"
   },
   "source": [
    "\n",
    "\n",
    "Воспользовавшись предобученной моделью [ResNet](https://pytorch.org/hub/pytorch_vision_resnet/), мы построим классификатор изображений с кошками и собаками на датасете [KaggleCatsAndDogs](https://www.microsoft.com/en-us/download/details.aspx?id=54765).\n",
    "\n",
    "Модель ResNet построена на свёртках. Эта матричная операция занимает много времени, будучи выполняемой на CPU. Архитектура CUDA позволяет существенно ускорить вычисление матричных операций благодаря параллельным вычислениям и использованию графических процессоров. Именно поэтому с этим ноутбуком лучше работать в Google Colab, так как он даёт возможность работы с видеокартой.\n",
    "\n",
    "### 1. Готовимся к работе.\n",
    "- Подключаем Google Drive(где должен лежать датасет скачанный KaggleCatsAndDogs).\n",
    "- Устанавливаем и импортируем необходимые библиотеки.\n",
    "- Извлекаем данные из архива."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJaSaJ8TFrfL",
    "outputId": "914e5366-978e-4bcd-86d9-c530ca5d02f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RtuKms_ORMM",
    "outputId": "87a17be8-48aa-4129-ad8a-35ba66677f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CDLA-Permissive-2.0.pdf   \u001b[0m\u001b[01;34mdrive\u001b[0m/   \u001b[01;34mPetImages\u001b[0m/  'readme[1].txt'   \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sTr8_mLwh2AG"
   },
   "outputs": [],
   "source": [
    "#!pip install torchinfo\n",
    "#!unzip \"/content/drive/MyDrive/Skillbox/ML Advanced/kagglecatsanddogs_5340.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vNqL83I5h8LI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize, ToPILImage\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bjrAOWVFZ9e"
   },
   "source": [
    "### 2. Готовим датасет.\n",
    "- Описываем класс кастомного датасета, наследуясь от `torch.utils.data.Dataset`\n",
    "- Загружаем датасет и делим его на тренировочную и валидационную выборки.\n",
    "- Оборачиваем датасеты в DataLoader.\n",
    "\n",
    "нормируем и центрируем наши данные не на (0.5, 0.5), а на заранее вычисленные среднее и корень из дисперсии изображений из датасета ImageNET. Так мы приближаем наши данные к тому, с чем училась работать модель ResNet. По этой же причине мы приводим все данные к размеру 224 × 224 пикселя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrEeueMVgfAa",
    "outputId": "e319215b-a5ea-4e19-c195-4cef3a647e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CDLA-Permissive-2.0.pdf   \u001b[0m\u001b[01;34mdrive\u001b[0m/   \u001b[01;34mPetImages\u001b[0m/  'readme[1].txt'   \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "80K3zoHrh8NZ"
   },
   "outputs": [],
   "source": [
    "class CatsDogsDataset(Dataset):\n",
    "    def __init__(self, datapath, transform=None):\n",
    "        super(CatsDogsDataset, self).__init__()\n",
    "        self.paths = []  # пути до картинок\n",
    "        self.labels = [] # labels картинок\n",
    "        # кошкам сделали соответствие - 0, собакам -1\n",
    "        for y, cls in enumerate(['Cat', 'Dog']): \n",
    "            p_tmp = glob(os.path.join(datapath, cls, '*.jpg')) # для каждого класса создаем список изображений\n",
    "            l_tmp = [y] * len(p_tmp)                           # для каждого класса создаем список labels\n",
    "            # добавляем списки к self.paths и self.labels\n",
    "            self.paths.extend(p_tmp)\n",
    "            self.labels.extend(l_tmp)\n",
    "            # добавляем transform\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths) # длина датасета это длина листа с путями\n",
    "\n",
    "    def __getitem__(self, idx): # метод __getitem__ принимает индексы элементов в датасете и возвращает изображения и label\n",
    "        img = Image.open(self.paths[idx]) # считываем изображение\n",
    "        img = img.convert('RGB')          # !!! загружаем изображения с одним каналом !!!\n",
    "        label = self.labels[idx]          # сохраняем label\n",
    "\n",
    "        if self.transform is not None:    # применяем transform\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ghPubqHM2GqZ"
   },
   "outputs": [],
   "source": [
    "dataset = CatsDogsDataset(datapath='/content/PetImages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeDdi7CBpIjO",
    "outputId": "3e0c2b46-0e12-4213-b887-50184365b98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина датасета: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина датасета:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O9z-nMJXIvba",
    "outputId": "e944bcff-5bfb-4d00-d480-97b0e533f302"
   },
   "outputs": [],
   "source": [
    "dataset = CatsDogsDataset('/content/PetImages')\n",
    "for i in range(10):\n",
    "    display(dataset[i] [0]) # так смотрим картинку\n",
    "    display(dataset[-i] [0])\n",
    "# а так смотрим пару - img, label\n",
    "for i in range(10):\n",
    "    display(dataset[i])\n",
    "    display(dataset[-i])\n",
    "\n",
    "# for i in range(10):\n",
    "#     display(dataset[i % len(dataset)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gtGkH08qRpci"
   },
   "outputs": [],
   "source": [
    "# from torchvision.transforms import Lambda\n",
    "# import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChQy2gPTh8Py",
    "outputId": "630485b4-64f8-4143-930c-c769e698603c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 5000\n"
     ]
    }
   ],
   "source": [
    "# делаем тензор\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Resize((224, 224)), # установим размер\n",
    "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # нормализуем - среднее и корень из дисперсии...\n",
    "])\n",
    "\n",
    "dataset = CatsDogsDataset('/content/PetImages', transform=transform)\n",
    "\n",
    "random_generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2], generator=random_generator)\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000)\n",
    "\n",
    "# #распечатать форму и тип данных тензора изображений в начале цикла обучения\n",
    "# for step, (data, target) in enumerate(train_loader):\n",
    "#     data_transformed = transform(data)\n",
    "#     print(f'Data shape: {data_transformed.shape}, Data type: {data_transformed.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_rvUZirFZ9e"
   },
   "source": [
    "### 3. Собираем модель.\n",
    "- Скачиваем веса обученной модели ResNet, например resnet-50.\n",
    "- Замораживаем параметры модели путём отключения для них процесса вычисления градиентов и обновления весов.\n",
    "- Меняем последний слой под задачу бинарной классификации.\n",
    "\n",
    "Для задачи бинарной классификации мы выберем бинарную кросс-энтропию в качестве лосса — [BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html). В отличие от CrossEntropyLoss, BCELoss ожидает на вход именно вероятность принадлежности семпла к целевому классу. Именно поэтому нам обязательно нужно применить сигмоиду к выходу линейного слоя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2M6dQqyh8SF",
    "outputId": "9970aecc-c4f4-4ad1-9db5-43f355470e74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 181MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 1000]                 --\n",
       "├─Conv2d: 1-1                            [1, 64, 112, 112]         9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         128\n",
       "├─ReLU: 1-3                              [1, 64, 112, 112]         --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-5                        [1, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-1                   [1, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 256, 56, 56]          512\n",
       "│    │    └─Sequential: 3-9              [1, 256, 56, 56]          16,896\n",
       "│    │    └─ReLU: 3-10                   [1, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-2                   [1, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-11                 [1, 64, 56, 56]           16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-13                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-14                 [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-16                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-17                 [1, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [1, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-19                   [1, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-3                   [1, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-20                 [1, 64, 56, 56]           16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-22                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-23                 [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-25                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-26                 [1, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-28                   [1, 256, 56, 56]          --\n",
       "├─Sequential: 1-6                        [1, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-4                   [1, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 128, 56, 56]          32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-31                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-32                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-34                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-35                 [1, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [1, 512, 28, 28]          1,024\n",
       "│    │    └─Sequential: 3-37             [1, 512, 28, 28]          132,096\n",
       "│    │    └─ReLU: 3-38                   [1, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-5                   [1, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-39                 [1, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-41                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-42                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-44                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-45                 [1, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [1, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-47                   [1, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-6                   [1, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-48                 [1, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-50                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-51                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-53                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-54                 [1, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [1, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-56                   [1, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-7                   [1, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-57                 [1, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-59                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-60                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-62                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-63                 [1, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [1, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-65                   [1, 512, 28, 28]          --\n",
       "├─Sequential: 1-7                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-8                   [1, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-66                 [1, 256, 28, 28]          131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-68                   [1, 256, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-69                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-71                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-72                 [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [1, 1024, 14, 14]         2,048\n",
       "│    │    └─Sequential: 3-74             [1, 1024, 14, 14]         526,336\n",
       "│    │    └─ReLU: 3-75                   [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-9                   [1, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-76                 [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-78                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-79                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-81                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-82                 [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-84                   [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-10                  [1, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-85                 [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-87                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-88                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-90                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-91                 [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-93                   [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-11                  [1, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-94                 [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-96                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-97                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-99                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-100                [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-102                  [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-12                  [1, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-103                [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-105                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-106                [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-108                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-109                [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-111                  [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-13                  [1, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-112                [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-114                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-115                [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-117                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-118                [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-120                  [1, 1024, 14, 14]         --\n",
       "├─Sequential: 1-8                        [1, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-14                  [1, 2048, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-121                [1, 512, 14, 14]          524,288\n",
       "│    │    └─BatchNorm2d: 3-122           [1, 512, 14, 14]          1,024\n",
       "│    │    └─ReLU: 3-123                  [1, 512, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-124                [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-125           [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-126                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-127                [1, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-128           [1, 2048, 7, 7]           4,096\n",
       "│    │    └─Sequential: 3-129            [1, 2048, 7, 7]           2,101,248\n",
       "│    │    └─ReLU: 3-130                  [1, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-15                  [1, 2048, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-131                [1, 512, 7, 7]            1,048,576\n",
       "│    │    └─BatchNorm2d: 3-132           [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-133                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-134                [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-135           [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-136                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-137                [1, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-138           [1, 2048, 7, 7]           4,096\n",
       "│    │    └─ReLU: 3-139                  [1, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-16                  [1, 2048, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-140                [1, 512, 7, 7]            1,048,576\n",
       "│    │    └─BatchNorm2d: 3-141           [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-142                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-143                [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-144           [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-145                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-146                [1, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-147           [1, 2048, 7, 7]           4,096\n",
       "│    │    └─ReLU: 3-148                  [1, 2048, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 2048, 1, 1]           --\n",
       "├─Linear: 1-10                           [1, 1000]                 2,049,000\n",
       "==========================================================================================\n",
       "Total params: 25,557,032\n",
       "Trainable params: 25,557,032\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.09\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 177.83\n",
       "Params size (MB): 102.23\n",
       "Estimated Total Size (MB): 280.66\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "summary(resnet, input_size=(1, 3, 224, 224)) # архитектура свертки..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bcs_ZQDeGfI8"
   },
   "outputs": [],
   "source": [
    "# итог предыдущей свертки - ветор Linear: 1-10 [1, 1000] 1000 элементов (классов)\n",
    "# а нам нужно ДВА класса - кот собака\n",
    "# заменяем последний слой Linear: 1-10\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False #  предиктор учить уже не будем(считать градиеты и обновлять веса ), оставим как есть...\n",
    "\n",
    "fc_inputs = resnet.fc.in_features # в слое AdaptiveAvgPool2d перед Linear 2048 входных фичей\n",
    "resnet.fc = nn.Sequential(        # заменяем на наш линейный слой\n",
    "    nn.Linear(fc_inputs, 1),      # тут вероятность, т.е. число от 0 до 1\n",
    "    nn.Sigmoid()                  # в наш слой добавили сигмоиду чтобы на выходе было от 0 до 1 (бинарная классификация)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHEL561OFZ9f"
   },
   "source": [
    "### 4. Обучаем модель и сохраняем веса.\n",
    "Пишем функции `train()` и `validate()`. Здесь добавится новый аргумент функций — `device`, так как мы хотим работать с моделью на GPU, но должны иметь возможность запустить её также и на CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cebVBfInh8UT"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre, device): # тут + параметр device\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        print(f'Epoch: {epoch}')\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            target = target.to(torch.float32)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f'Iter: {step} \\tLoss: {loss.item()}')\n",
    "\n",
    "        print(f'Mean Train Loss: {loss_sum / (step + 1):.6f}', end='\\n\\n')\n",
    "\n",
    "        if epoch % val_fre == 0:\n",
    "            validate(model, val_loader, device)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (data, target) in enumerate(val_loader):\n",
    "        target = target.to(torch.float32)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        pred = torch.round(output)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}')\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0wJFy39h8WS",
    "outputId": "fd99beda-e20b-4d1b-c333-3cf24dd07063",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iter: 0 \tLoss: 0.6926815509796143\n",
      "Iter: 10 \tLoss: 0.6715524792671204\n",
      "Iter: 20 \tLoss: 0.6633674502372742\n",
      "Iter: 30 \tLoss: 0.6525170207023621\n",
      "Iter: 40 \tLoss: 0.627971351146698\n",
      "Iter: 50 \tLoss: 0.611298143863678\n",
      "Iter: 60 \tLoss: 0.5973123908042908\n",
      "Iter: 70 \tLoss: 0.5961748957633972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 80 \tLoss: 0.581307053565979\n",
      "Iter: 90 \tLoss: 0.5638806819915771\n",
      "Mean Train Loss: 0.620319\n",
      "\n",
      "Val Loss: 0.556834 \tAccuracy: 0.8932\n",
      "Epoch: 1\n",
      "Iter: 0 \tLoss: 0.5562268495559692\n",
      "Iter: 10 \tLoss: 0.5475522875785828\n",
      "Iter: 20 \tLoss: 0.5416414737701416\n",
      "Iter: 30 \tLoss: 0.5287393927574158\n",
      "Iter: 40 \tLoss: 0.516267716884613\n",
      "Iter: 50 \tLoss: 0.5108008980751038\n",
      "Iter: 60 \tLoss: 0.4997338056564331\n",
      "Iter: 70 \tLoss: 0.49052056670188904\n",
      "Iter: 80 \tLoss: 0.5015973448753357\n",
      "Iter: 90 \tLoss: 0.4736279249191284\n",
      "Mean Train Loss: 0.510059\n",
      "\n",
      "Val Loss: 0.465012 \tAccuracy: 0.9494\n",
      "Epoch: 2\n",
      "Iter: 0 \tLoss: 0.4776754677295685\n",
      "Iter: 10 \tLoss: 0.4720796048641205\n",
      "Iter: 20 \tLoss: 0.44427409768104553\n",
      "Iter: 30 \tLoss: 0.44800499081611633\n",
      "Iter: 40 \tLoss: 0.42262670397758484\n",
      "Iter: 50 \tLoss: 0.4334222972393036\n",
      "Iter: 60 \tLoss: 0.4309605360031128\n",
      "Iter: 70 \tLoss: 0.4094736874103546\n",
      "Iter: 80 \tLoss: 0.3900860846042633\n",
      "Iter: 90 \tLoss: 0.407488077878952\n",
      "Mean Train Loss: 0.433157\n",
      "\n",
      "Val Loss: 0.401925 \tAccuracy: 0.964\n",
      "Epoch: 3\n",
      "Iter: 0 \tLoss: 0.4064137935638428\n",
      "Iter: 10 \tLoss: 0.3983405530452728\n",
      "Iter: 20 \tLoss: 0.3861392140388489\n",
      "Iter: 30 \tLoss: 0.3968791961669922\n",
      "Iter: 40 \tLoss: 0.3985254466533661\n",
      "Iter: 50 \tLoss: 0.3717828691005707\n",
      "Iter: 60 \tLoss: 0.3727726936340332\n",
      "Iter: 70 \tLoss: 0.37396296858787537\n",
      "Iter: 80 \tLoss: 0.36974233388900757\n",
      "Iter: 90 \tLoss: 0.36035314202308655\n",
      "Mean Train Loss: 0.378165\n",
      "\n",
      "Val Loss: 0.355672 \tAccuracy: 0.9716\n",
      "Epoch: 4\n",
      "Iter: 0 \tLoss: 0.3692013919353485\n",
      "Iter: 10 \tLoss: 0.34460559487342834\n",
      "Iter: 20 \tLoss: 0.34451568126678467\n",
      "Iter: 30 \tLoss: 0.35722899436950684\n",
      "Iter: 40 \tLoss: 0.3417219817638397\n",
      "Iter: 50 \tLoss: 0.32599562406539917\n",
      "Iter: 60 \tLoss: 0.3428223729133606\n",
      "Iter: 70 \tLoss: 0.31360524892807007\n",
      "Iter: 80 \tLoss: 0.32871779799461365\n",
      "Iter: 90 \tLoss: 0.3071862459182739\n",
      "Mean Train Loss: 0.336484\n",
      "\n",
      "Val Loss: 0.318724 \tAccuracy: 0.9734\n",
      "Epoch: 5\n",
      "Iter: 0 \tLoss: 0.31098392605781555\n",
      "Iter: 10 \tLoss: 0.3229944407939911\n",
      "Iter: 20 \tLoss: 0.30549806356430054\n",
      "Iter: 30 \tLoss: 0.31976118683815\n",
      "Iter: 40 \tLoss: 0.29647231101989746\n",
      "Iter: 50 \tLoss: 0.3102867007255554\n",
      "Iter: 60 \tLoss: 0.30856695771217346\n",
      "Iter: 70 \tLoss: 0.29843616485595703\n",
      "Iter: 80 \tLoss: 0.2870527505874634\n",
      "Iter: 90 \tLoss: 0.3045780062675476\n",
      "Mean Train Loss: 0.304820\n",
      "\n",
      "Val Loss: 0.291820 \tAccuracy: 0.9754\n",
      "Epoch: 6\n",
      "Iter: 0 \tLoss: 0.2676587700843811\n",
      "Iter: 10 \tLoss: 0.29414549469947815\n",
      "Iter: 20 \tLoss: 0.28452470898628235\n",
      "Iter: 30 \tLoss: 0.3060906231403351\n",
      "Iter: 40 \tLoss: 0.28251317143440247\n",
      "Iter: 50 \tLoss: 0.2747378945350647\n",
      "Iter: 60 \tLoss: 0.25067779421806335\n",
      "Iter: 70 \tLoss: 0.28447550535202026\n",
      "Iter: 80 \tLoss: 0.25616851449012756\n",
      "Iter: 90 \tLoss: 0.26627233624458313\n",
      "Mean Train Loss: 0.278670\n",
      "\n",
      "Val Loss: 0.268445 \tAccuracy: 0.977\n",
      "Epoch: 7\n",
      "Iter: 0 \tLoss: 0.24899742007255554\n",
      "Iter: 10 \tLoss: 0.27048760652542114\n",
      "Iter: 20 \tLoss: 0.28448212146759033\n",
      "Iter: 30 \tLoss: 0.2573462724685669\n",
      "Iter: 40 \tLoss: 0.2519384026527405\n",
      "Iter: 50 \tLoss: 0.274954617023468\n",
      "Iter: 60 \tLoss: 0.24067507684230804\n",
      "Iter: 70 \tLoss: 0.26706889271736145\n",
      "Iter: 80 \tLoss: 0.23475217819213867\n",
      "Iter: 90 \tLoss: 0.2534719407558441\n",
      "Mean Train Loss: 0.258512\n",
      "\n",
      "Val Loss: 0.248749 \tAccuracy: 0.9774\n",
      "Epoch: 8\n",
      "Iter: 0 \tLoss: 0.25042828917503357\n",
      "Iter: 10 \tLoss: 0.24125653505325317\n",
      "Iter: 20 \tLoss: 0.24732623994350433\n",
      "Iter: 30 \tLoss: 0.24861808121204376\n",
      "Iter: 40 \tLoss: 0.2623269259929657\n",
      "Iter: 50 \tLoss: 0.24437299370765686\n",
      "Iter: 60 \tLoss: 0.2491168975830078\n",
      "Iter: 70 \tLoss: 0.22822873294353485\n",
      "Iter: 80 \tLoss: 0.23747555911540985\n",
      "Iter: 90 \tLoss: 0.21861164271831512\n",
      "Mean Train Loss: 0.241836\n",
      "\n",
      "Val Loss: 0.233476 \tAccuracy: 0.9788\n",
      "Epoch: 9\n",
      "Iter: 0 \tLoss: 0.21278876066207886\n",
      "Iter: 10 \tLoss: 0.2214946299791336\n",
      "Iter: 20 \tLoss: 0.21690459549427032\n",
      "Iter: 30 \tLoss: 0.21205374598503113\n",
      "Iter: 40 \tLoss: 0.24567164480686188\n",
      "Iter: 50 \tLoss: 0.24463465809822083\n",
      "Iter: 60 \tLoss: 0.2035434991121292\n",
      "Iter: 70 \tLoss: 0.22806639969348907\n",
      "Iter: 80 \tLoss: 0.22006937861442566\n",
      "Iter: 90 \tLoss: 0.2235950082540512\n",
      "Mean Train Loss: 0.227607\n",
      "\n",
      "Val Loss: 0.219485 \tAccuracy: 0.979\n",
      "Val Loss: 0.219485 \tAccuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "loss_f = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=1e-3)\n",
    "\n",
    "n_epoch = 10\n",
    "val_fre = 1\n",
    "\n",
    "device = 'cuda'\n",
    "#device = 'cpu'\n",
    "\n",
    "train(resnet, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre, device)\n",
    "\n",
    "validate(resnet, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaP2vPuIMcsu",
    "outputId": "7fca86b5-338f-431b-917a-0e6682624bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 14253 Oct 24 06:48 /content/PetImages/Cat/666.jpg\n"
     ]
    }
   ],
   "source": [
    "#ls -l /content/PetImages/Cat/666.jpg # ошибка - нулевое содержимое, скопировал в него 665.jpg и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "xWS76xj3ZrYv"
   },
   "outputs": [],
   "source": [
    "#cp /content/PetImages/Cat/665.jpg /content/PetImages/Cat/666.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPiVJdhiS5Hm",
    "outputId": "4eb835ad-f0f8-4f9f-cb62-baec08a9e9e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 6555 Oct 24 06:59 /content/PetImages/Dog/11702.jpg\n"
     ]
    }
   ],
   "source": [
    "#ls -l /content/PetImages/Dog/11702.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xxucPW5vPhhI"
   },
   "outputs": [],
   "source": [
    "#cp /content/PetImages/Dog/11701.jpg /content/PetImages/Dog/11702.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AUrINycCORMQ"
   },
   "outputs": [],
   "source": [
    "torch.save(resnet.fc.state_dict(), '/content/drive/MyDrive/Skillbox/ML Advanced/resnet_fc.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoELmqZaORMQ",
    "outputId": "32c3c109-eca4-4eaa-e39c-5a75140d2f6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-7de92500e102>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet.fc.load_state_dict(torch.load('/content/drive/MyDrive/Skillbox/ML Advanced/resnet_fc.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.fc.load_state_dict(torch.load('/content/drive/MyDrive/Skillbox/ML Advanced/resnet_fc.pth'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
